---
title: "Buan6356_Homework3_UdayakumarA"
author: "Anjana"
date: "4/4/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(caret)
library(dplyr)
library(MASS)
library(gains)
library(base)
library(ggplot2)


```


```{r importing data}
spambase.dt <- fread("spambase.data")
spambase.dt <- data.frame(spambase.dt)
#Read the spambase.names file
names <- read.csv("spambase.names",sep=":",header = FALSE,skip = 33)
names.mat <- as.matrix(names[-2])
colnames(spambase.dt) <- c(names.mat,"Spam/nonSpam")
```


```{r partitioning data}
set.seed(42)
train.index <- createDataPartition(spambase.dt$`Spam/nonSpam`, p =0.8,list = FALSE)
train.dt <- spambase.dt[train.index,]
valid.dt <- spambase.dt[-train.index,]
```


```{r normalising data}
spambase.norm <- preProcess(train.dt[,1:57],method = c("center","scale"))
train.norm <- predict(spambase.norm,train.dt)
valid.norm <- predict(spambase.norm,valid.dt)
```


```{r Identify 10 predictors}
#Question1
#Identification of spam or non spam rows;Spam = 1,nonspam = 0
spam <- spambase.dt %>% filter(spambase.dt$`Spam/nonSpam`== 1)
nonspam <- spambase.dt %>% filter(spambase.dt$`Spam/nonSpam` == 0)
av.spam <- colMeans(spam[,1:57])
av.nonspam <- colMeans(nonspam[,1:57])
difference <- abs(av.spam - av.nonspam)
difference 
difference.vec <- as.vector(difference)
names(difference.vec) <- names(difference)
topten <- head(sort(difference.vec,decreasing = TRUE),10)
topten.predictors <- names(topten)
#The top 10 predictors with highest difference in mean values between spam and 
#non spam
topten.predictors
```
1)The top 10 predictors are as follows
  1)Capital_run_length_total
  2)capital_run_length_longest
  3)capital_run_length_average
  4)word_freq_george
  5)word_freq_you
  6)word_freq_your
  7)word_freq_hp
  8)word_freq_free
  9)word_freq_hpl
  10)char_freq_!

```{r question 2 Peforming LDA}
#Question 2
toptenvar <- names(topten)
addcol <- c(toptenvar,'Spam/nonSpam')
train.data <- train.norm[, addcol]
valid.data <- valid.norm[, addcol]
ldam <- lda(`Spam/nonSpam`~ .,data = train.data)
ldam
```


```{r question 3 Prior probabilities}
#Question 3
pp <- ldam$prior
pp
```
The prior probabilities are as follows
   0 (Non spam) - 0.6036403
   1(Spam)      -0.3963597

```{r question 4:Coefficients of Linear discriminants }
#Question 4
ldam$scaling
```
4)The following are the coefficients of linear discriminants
                                  LD1
capital_run_length_total    0.41440081
capital_run_length_longest  0.08693844
capital_run_length_average  0.06514596
word_freq_george           -0.20131729
word_freq_you               0.22218685
word_freq_your              0.55570537
word_freq_hp               -0.23537035
word_freq_free              0.43382365
word_freq_hpl              -0.16541775
`char_freq_!`               0.29626807
The coefficients multiplied by corresponding predictive variables result in the LDA score.

```{r Question 5: Generating linear discriminants }
#Question 5
pred <- predict(ldam,valid.data)
toppred <- head(pred$posterior,20)
toppred
```
5)The following are the top 20 linear discriminants generated by the model.
	   0	              1
5	  0.64589615	0.3541039
11	0.5788967	  0.4211033
21	0.82402312	0.1759769
28	0.74794028	0.2520597
40	0.40363019	0.5963698
42	0.32500406	0.6749959
76	0.08740194	0.9125981
85	0.79762191	0.2023781
88	0.31855452	0.6814455
90	0.86896577	0.1310342
107	0.7455409	  0.2544591
117	0.60832931	0.3916707
120	0.2222072	  0.7777928
123	0.05146256	0.9485374
128	0.4509951	  0.5490049
129	0.34035938	0.6596406
133	0.4614059	  0.5385941
136	0.41066757	0.5893324
137	0.41066757	0.5893324
145	0.09008854	0.9099115
129	0.34035938	0.6596406
133	0.4614059	  0.5385941
136	0.41066757	0.5893324
137	0.41066757	0.5893324
145	0.09008854	0.9099115
The LDA score is converted into probabilities of belonging to either spam or non spam class for easy interpretation.It is then compared against either a pre-defined value(0.5/0.5) or compare between the probabilities of these 2 classes and the class with the higher probability is stored. For example, in the first record shown above, the probability of belonging to non spam class(0.64) is greater than the probability of belinging to spam(0.35).Hence that particular record would be classified as Non Spam.


```{r Question 7 LDA Plots }
#Question 7
trainpred <- lda(`Spam/nonSpam`~.,data = train.data)
plot(trainpred, main = "LDA plot of training dataset")
validpred <- lda(`Spam/nonSpam`~.,data=valid.data)
plot(validpred, main =" LDA plot of validation dataset")
```
Q.7)We see that in these plots the values are towards the left of 0 for Non Spam and the values are towards the right of 0 for Spam.This shows that LDA has maximised the separation of the classes.

```{r Question 8 confusion matrix }
#Question 8
confmat <- table(pred$class,valid.data$`Spam/nonSpam`)
confusionMatrix(confmat)
```
Q.8) Consider the class Non spam to be of interest.
Recall = True positives/(true positive+false negative) => 520/(520+46) =0.9187
Precision = True Positives/(True positive+False Positive) =>520/(520+118)=0.8150

A precision of 0.8150 means that the model correctly classifies non spam mail correctly for about 81.50%.

Recall tells us how many mails was the model able to correctly identify as non spam.
```{r Question 9 Lift and decile charts }
#Question 9
lift <- gains(as.numeric(valid.data$`Spam/nonSpam`),pred$x[,1])
plot(c(0,lift$cume.pct.of.total*sum(as.numeric(valid.data$`Spam/nonSpam`)))
     ~c(0,lift$cume.obs),
     xlab = 'No.Of.Cases', ylab = 'Cumulative',
     main = "Lift Chart for Predictions",
     col = "blue",
     type = "l")
lines(c(0,sum(as.numeric(valid.data$`Spam/nonSpam`)))~c(0,dim(valid.norm)[1]), lty = 5)
decile <- lift$mean.resp/mean(as.numeric(valid.data$`Spam/nonSpam`))
barplot(decile,names.arg = lift$depth,ylim =c(0,3),col="blue",xlab = "Percentile",ylab = "Mean Response",main = "Decile chart")
```
Q.9)From Lift and decile charts we can see that our model performs well. The line below the curve in the lift chart tells us the no.of records that the model predicts in random assignemnt.When we compare the line to the curve we see that the model predicts more number of records correctly as opposed to prediction by random assignment, For example;If we choose top 600 records, the model correctly predicts for about 300 records which is higher compared to correct prediction of 200 records by random assignemnt.

```{r Question 10 LDA using probability threshold of 0.3 }
#Question 10
confusionMatrix(as.factor(ifelse(pred$x>0.3,1,0)),pred$class)
```
Q.10)We see that the accuracy has increased to 97% when we have the probability threshold as 0.3.
 
6)There is one linear discriminant in the model. As there are only 2 categories(Spam/not spam), one linear discriminant would suffice



## R Markdown



This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

`

```

